{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import module and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./dataset/train.csv\")\n",
    "test = pd.read_csv(\"./dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. test Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test Dictionary\n",
    "    1. Survival : survival or not (0 : No, 1 : Yes)  \n",
    "    2. pclass : Ticket class  \n",
    "    3. sex : sex  \n",
    "    4. Age : age in years  \n",
    "    5. sibsp : # of sibilings / spouses aborad the titanic  \n",
    "    6. parch : # of parents / children aborad the titanic  \n",
    "    7. ticket : Ticket number  \n",
    "    8. fare : Passenger fare  \n",
    "    9. cabin : Cabin number  \n",
    "    10. embarked : Port of Embarkation (C : Cherborug, Q : Queenstown, S : Southampton)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각 891개의 데이터가 있으며 12개의 column으로 이루어져 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age에서 177개, Cabin에서 687개, Embarked에서 2개의 결측치가 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각의 데이터는 아래와 같이 이루어져 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 데이터의 분포는 아래와 같음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test test는 총 418개의 데이터로 이루어져있고 11개의 column으로 이루져있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 데이터는 Age에서 86개, Cabin에서 327개의 결측치가 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 데이터의 분포는 아래와 같음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Analyzation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name column의 경우 Prefix를 정규표현식을 이용해 추출함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Prefix\"] = train[\"Name\"].str.extract(\"([A-Za-z]+)\\.\")\n",
    "test[\"Prefix\"] = test[\"Name\"].str.extract(\"([A-Za-z]+)\\.\")\n",
    "train[\"Prefix\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Prefix\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추출된 Prefix를 학습에 사용할 수 있도록 int화 시켜줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_dict = {\"Mr\":0, \"Miss\":1, \"Mrs\":2, \"Master\":3, \"Dr\":4, \"Rev\":4, \"Major\":4, \"Col\":4, \"Mlle\":4, \"Ms\":4, \"Countess\":4, \"Jonkheer\":4, \"Lady\":4, \"Capt\":4, \"Don\":4, \"Sir\":4, \"Mme\":4, \"Dona\":4}\n",
    "train[\"Prefix\"] = train[\"Prefix\"].map(pre_dict)\n",
    "test[\"Prefix\"] = test[\"Prefix\"].map(pre_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Prefix\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Prefix\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embarked column의 결측치를 채워넣음. Embarked의 경우, 절대적 다수인 \"S\"로 채워줍니다. Test의 경우에는 Embarked Column에 결측치가 없으므로 Train 데이터에만 작업을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Embarked\"].fillna(train[\"Embarked\"].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sb.heatmap(data=train.corr(), annot=True, fmt='.2f', linewidths=.5, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age의 경우, Pclass와 Age의 Correlation이 가장 크므로, 각 Pclass의 평균치를 입력해줍니다.  \n",
    "Test의 경우는 Train에서의 평균치를 삽입해줍니다.  \n",
    "Test의 존재하는 Fare의 결측치 경우, Fare와 Pclass의 Correlation이 가장 크므로, Train의 각 Pclass의 평균치를 입력해줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.barplot(x=\"Pclass\", y=\"Age\", ci=None, data= train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.barplot(x=\"Pclass\", y=\"Fare\", ci=None, data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Age\"].fillna(train.groupby(\"Pclass\")[\"Age\"].transform(\"mean\"), inplace=True)\n",
    "\n",
    "# for test\n",
    "for idx in range(len(test)):\n",
    "    if np.isnan(test[\"Age\"][idx]):\n",
    "        test[\"Age\"][idx] = train[train[\"Pclass\"] == test[\"Pclass\"][idx]][\"Age\"].mean()\n",
    "    if np.isnan(test[\"Fare\"][idx]):\n",
    "        test[\"Fare\"][idx] = train[train[\"Pclass\"] == test[\"Pclass\"][idx]][\"Fare\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 str 되어있는 Sex와 Embarked column또한 모델이 인식할 수 있도록 int화 시킴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_dict = {\"male\":0, \"female\":1}\n",
    "train[\"Sex\"] = train[\"Sex\"].map(s_dict)\n",
    "test[\"Sex\"] = test[\"Sex\"].map(s_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebk_dict = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "train[\"Embarked\"] = train[\"Embarked\"].map(ebk_dict)\n",
    "test[\"Embarked\"] = test[\"Embarked\"].map(ebk_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sib_dict = {0:0, 1:1, 2:2, 3:2, 4:2, 5:2, 8:2}\n",
    "train[\"SibSp\"] = train[\"SibSp\"].map(sib_dict)\n",
    "test[\"SibSp\"] = test[\"SibSp\"].map(sib_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parch_dict = {0:0, 1:1, 2:2, 3:2, 4:2, 5:2, 6:2, 9:2}\n",
    "train[\"Parch\"] = train[\"Parch\"].map(parch_dict)\n",
    "test[\"Parch\"] = test[\"Parch\"].map(parch_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이후 필요없는 label의 경우 drop을 시켜줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([\"PassengerId\", \"Name\", \"Cabin\", \"Ticket\"], axis=1, inplace=True)\n",
    "test.drop([\"Name\", \"Cabin\", \"Ticket\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 데이터에 존재하는 Outlier를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(train[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(train[\"Fare\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_outlier(data,col):\n",
    "    q3 = train[col].quantile(q=0.75)\n",
    "    q1 = train[col].quantile(q=0.25)\n",
    "    iqr = 1.5 * (q3-q1)\n",
    "    data.loc[data[col] < q1-iqr, col] = q1-iqr\n",
    "    data.loc[data[col] > q3+iqr, col] = q3+iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_outlier(train, \"Age\")\n",
    "change_outlier(test, \"Age\")\n",
    "change_outlier(train, \"Fare\")\n",
    "change_outlier(test, \"Fare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age와 Fare는 범위가 넓기때문에 4개의 범위로 grouping을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"Age\"] <=22.0, \"Age\"] = 0\n",
    "train.loc[(train[\"Age\"] >22.0) & (train[\"Age\"] <= 26.0), \"Age\"] = 1\n",
    "train.loc[(train[\"Age\"] >26.0) & (train[\"Age\"] <= 37.0), \"Age\"] = 2\n",
    "train.loc[train[\"Age\"] > 37.0, \"Age\"] = 3\n",
    "\n",
    "train.loc[train[\"Fare\"] <= 7.91, \"Fare\"] = 0\n",
    "train.loc[(train[\"Fare\"] > 7.91) & (train[\"Fare\"] <= 14.4542), \"Fare\"] = 1\n",
    "train.loc[(train[\"Fare\"] > 14.4542) & (train[\"Fare\"] <= 31), \"Fare\"] = 2\n",
    "train.loc[train[\"Fare\"] > 31, \"Fare\"] = 3\n",
    "train[\"Age\"] = train[\"Age\"].astype(\"int64\")\n",
    "train[\"Fare\"] = train[\"Fare\"].astype(\"int64\")\n",
    "\n",
    "\n",
    "test.loc[test[\"Age\"] <= 22.0, \"Age\"] = 0\n",
    "test.loc[(test[\"Age\"] > 22.0) & (test[\"Age\"] <= 26.0), \"Age\"] = 1\n",
    "test.loc[(test[\"Age\"] > 26.0) & (test[\"Age\"] <= 37.0), \"Age\"] = 2\n",
    "test.loc[test[\"Age\"] > 37, \"Age\"] = 3\n",
    "\n",
    "test.loc[test[\"Fare\"] <= 7.91, \"Fare\"] = 0\n",
    "test.loc[(test[\"Fare\"] > 7.91) & (test[\"Fare\"] <= 14.4542), \"Fare\"] = 1\n",
    "test.loc[(test[\"Fare\"] > 14.4542) & (test[\"Fare\"] <= 31), \"Fare\"] = 2\n",
    "test.loc[test[\"Fare\"] > 31, \"Fare\"] = 3\n",
    "\n",
    "test[\"Age\"] = test[\"Age\"].astype(\"int64\")\n",
    "test[\"Fare\"] = test[\"Fare\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리 후 Correlation 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sb.heatmap(data=train.corr(), annot=True, fmt='.2f', linewidths=.5, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation 0.1이상의 column을 제외한 데이터 drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['SibSp', 'Age']\n",
    "train.drop(drop_list, axis=1)\n",
    "test.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification module\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"Survived\"]\n",
    "x_train = train.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logis = LogisticRegression()\n",
    "logis.fit(x_train, y_train)\n",
    "logis_score = logis.score(x_train, y_train)\n",
    "print(f\"Logistic regression Score: {logis_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine(SVM)\n",
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "svm_score = svm.score(x_train, y_train)\n",
    "print(f\"SVM score: {svm_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(x_train, y_train)\n",
    "knn_score = knn.score(x_train, y_train)\n",
    "print(f\"KNN score: {knn_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(x_train, y_train)\n",
    "tree_score = tree.score(x_train, y_train)\n",
    "print(f\"Decision Tree Score: {tree_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()\n",
    "forest.fit(x_train, y_train)\n",
    "forest_score = forest.score(x_train, y_train)\n",
    "print(f\"Random Forest score: {forest_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA()\n",
    "lda.fit(x_train, y_train)\n",
    "lda_score = lda.score(x_train, y_train)\n",
    "print(f\"LDA score: {lda_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RidgeClassifier()\n",
    "ridge.fit(x_train, y_train)\n",
    "ridge_score = ridge.score(x_train, y_train)\n",
    "print(f\"Ridge score: {ridge_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test.copy()\n",
    "test_pred = test_pred.drop(\"PassengerId\", axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(test_pred)\n",
    "submission = pd.DataFrame({\"PassengerId\" : test[\"PassengerId\"], \"Survived\":y_pred})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train with K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML\n",
    "from pycaret import classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ml = classification.setup(data=train, target=\"Survived\", fold_strategy='stratifiedkfold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ml_result = classification.compare_models(fold=5, round=3, sort=\"Accuracy\", n_select=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=20, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---- Logistic Regression ----\")\n",
    "logis_k = LogisticRegression()\n",
    "logis_k_score = cross_val_score(logis_k, x_train, y_train, cv=kfold, n_jobs=1, scoring=\"accuracy\")\n",
    "print(logis_k_score)\n",
    "print(f\"Average logis_k score: {np.mean(logis_k_score)} \\n\")\n",
    "\n",
    "print(\"---- Support Vector Machine ----\")\n",
    "svm_k = SVC()\n",
    "svm_k_score = cross_val_score(svm_k, x_train, y_train, cv=kfold, n_jobs=1, scoring='accuracy')\n",
    "print(svm_k_score)\n",
    "print(f\"Average svm_k score: {np.mean(svm_k_score)} \\n\")\n",
    "\n",
    "print(\"---- K-Nerest Neighbor ----\")\n",
    "knn_k = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_k_score = cross_val_score(knn_k, x_train, y_train, cv=kfold, n_jobs=1, scoring=\"accuracy\")\n",
    "print(knn_k_score)\n",
    "print(f\"Average knn_k score: {np.mean(knn_k_score)} \\n\")\n",
    "\n",
    "print(\"---- Decision Tree ----\")\n",
    "tree_k = DecisionTreeClassifier()\n",
    "tree_k_score = cross_val_score(tree_k, x_train, y_train, cv=kfold, n_jobs=1, scoring=\"accuracy\")\n",
    "print(tree_k_score)\n",
    "print(f\"Average tree_k score: {np.mean(tree_k_score)} \\n\")\n",
    "\n",
    "print(\"---- Random Forest ----\")\n",
    "forest_k = RandomForestClassifier()\n",
    "forest_k_score = cross_val_score(forest_k, x_train, y_train, cv=kfold, n_jobs=1, scoring=\"accuracy\")\n",
    "print(forest_k_score)\n",
    "print(f\"Average forest_k score: {np.mean(forest_k_score)} \\n\")\n",
    "\n",
    "print(\"---- LDA ----\")\n",
    "lda_k = LDA()\n",
    "lda_k_score = cross_val_score(lda_k, x_train, y_train, cv=kfold, n_jobs=1, scoring=\"accuracy\")\n",
    "print(lda_k_score)\n",
    "print(f\"Average lda_k score: {np.mean(lda_k_score)} \\n\")\n",
    "\n",
    "print(\"---- Ridge ----\")\n",
    "ridge_k = RidgeClassifier()\n",
    "ridge_k_score = cross_val_score(ridge_k, x_train, y_train, cv=kfold, n_jobs=1, scoring=\"accuracy\")\n",
    "print(ridge_k_score)\n",
    "print(f\"Average ridge_k score: {np.mean(ridge_k_score)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_final = SVC()\n",
    "lda_final.fit(x_train, y_train)\n",
    "y_pred = lda_final.predict(test_pred)\n",
    "submission = pd.DataFrame({\"PassengerId\" : test[\"PassengerId\"], \"Survived\":y_pred})\n",
    "submission.to_csv(\"submission_kfold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizerCAT(trial, data, target):\n",
    "    param = {\n",
    "        'random_state':42,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 3500),\n",
    "        'depth': trial.suggest_int('depth', 6, 14),\n",
    "        'fold_permutation_block': trial.suggest_int('fold_permutation_block', 1, 256),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1),\n",
    "        'od_pval': trial.suggest_float('od_pval', 0, 1),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0, 4),\n",
    "    }\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(data, target, test_size=0.2)\n",
    "\n",
    "    model = CatBoostClassifier(**param)\n",
    "    model.fit(x_train, y_train, verbose= True)\n",
    "    score = accuracy_score(model.predict(x_valid), y_valid)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", sampler=TPESampler())\n",
    "x_train = train.drop([\"Survived\"], axis=1)\n",
    "y_train = train[\"Survived\"]\n",
    "study.optimize(lambda trial: optimizerCAT(trial, x_train, y_train), n_trials=5)\n",
    "\n",
    "print('Best trial : score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_parameter = {'n_estimators': [3472], 'depth': [11], 'fold_permutation_block': [201], 'learning_rate': [0.7135660214466232], 'od_pval': [0.14156911916283843], 'l2_leaf_reg': [1.3590814127726265]}\n",
    "cat = CatBoostClassifier(random_state=42, verbose=False)\n",
    "model = RandomizedSearchCV(cat, cat_parameter, cv=kfold, n_jobs=1)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_pred)\n",
    "submission = pd.DataFrame({\"PassengerId\" : test[\"PassengerId\"], \"Survived\":y_pred})\n",
    "submission.to_csv(\"submission_catboost.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
